{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "version_major": 2,
        "version_minor": 0,
        "state": {}
      }
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "Q1. What is multiprocessing in python? Why is it useful?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q1. Solution :\n\nMultiprocessing in Python refers to the capability of running multiple processes concurrently within a Python program. Each process operates independently and can execute its code simultaneously with other processes, leveraging multiple CPU cores or processors. This is different from multithreading, where multiple threads operate within the same process.\n\n### Why Multiprocessing is Useful:\n\n1. **Improved Performance**:\n   - Multiprocessing can significantly improve the performance of CPU-bound tasks by distributing the workload across multiple CPU cores. This allows the program to execute computations in parallel, reducing processing time.\n\n2. **True Parallelism**:\n   - Unlike multithreading, which is constrained by the Global Interpreter Lock (GIL) in Python, multiprocessing allows for true parallelism. Each process has its memory space, and multiple processes can execute simultaneously without contention for the GIL.\n\n3. **Utilization of Multiple Cores**:\n   - Modern computers often have multiple CPU cores. Multiprocessing enables applications to utilize these cores efficiently, maximizing computational power and throughput.\n\n4. **Isolation**:\n   - Processes in multiprocessing are isolated from each other, with their memory space. This isolation enhances robustness and reliability as issues in one process typically do not affect others.\n\n5. **Fault Tolerance**:\n   - Multiprocessing can enhance fault tolerance. If one process encounters an error or crashes, it generally does not impact other processes, reducing the risk of the entire program failing.\n\n6. **Task Parallelism**:\n   - Multiprocessing is suitable for task parallelism, where independent tasks can be executed concurrently. This is beneficial for scenarios such as data processing, simulations, and scientific computations.\n\n7. **Resource Management**:\n   - Multiprocessing provides tools for managing resources and communication between processes, such as shared memory, queues, pipes, and synchronization primitives like locks and semaphores.\n\nOverall, multiprocessing is a powerful technique in Python for achieving parallelism, improving performance, and efficiently utilizing hardware resources, especially in scenarios involving CPU-intensive computations or tasks that can be parallelized.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q2. What are the differences between multiprocessing and multithreading?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q2. Solution :\n\nThe differences between multiprocessing and multithreading in Python are significant and impact how concurrent tasks are executed within a program:\n\n1. **Definition**:\n   - **Multiprocessing**: Involves running multiple processes concurrently, each with its memory space and resources. Processes do not share memory by default and communicate through IPC (Inter-Process Communication).\n   - **Multithreading**: Involves running multiple threads (lightweight processes) concurrently within a single process. Threads share the same memory space and resources of the parent process.\n\n2. **Parallelism**:\n   - **Multiprocessing**: Allows for true parallelism as processes can run simultaneously across multiple CPU cores or processors. Suitable for CPU-bound tasks.\n   - **Multithreading**: Limited by the Global Interpreter Lock (GIL) in Python, which prevents true parallelism by allowing only one thread to execute Python bytecode at a time. Better suited for I/O-bound tasks.\n\n3. **Memory and Resource Sharing**:\n   - **Multiprocessing**: Processes have separate memory spaces and do not share variables by default. Communication between processes is achieved through mechanisms like queues, pipes, and shared memory.\n   - **Multithreading**: Threads share the same memory space and can access shared variables directly. However, this can lead to race conditions and requires synchronization mechanisms like locks and semaphores.\n\n4. **Isolation**:\n   - **Multiprocessing**: Processes are isolated from each other, providing better fault tolerance. Issues in one process typically do not affect others.\n   - **Multithreading**: Threads operate within the same process, making them more tightly coupled. Issues in one thread can potentially affect the entire process.\n\n5. **Scalability**:\n   - **Multiprocessing**: Scales well on multi-core systems as each process can utilize a separate CPU core.\n   - **Multithreading**: Limited scalability due to the GIL, which hinders performance gains on multi-core systems for CPU-bound tasks.\n\n6. **Complexity**:\n   - **Multiprocessing**: Generally more complex than multithreading due to inter-process communication and managing separate memory spaces.\n   - **Multithreading**: Simpler to implement but requires careful handling of shared resources to avoid race conditions and other concurrency issues.\n\nIn summary, multiprocessing offers true parallelism, better isolation, and scalability for CPU-bound tasks but involves more complexity and overhead. Multithreading is simpler to implement, suitable for I/O-bound tasks, but limited by the GIL and requires careful synchronization to avoid concurrency issues. The choice between multiprocessing and multithreading depends on the specific requirements and characteristics of the concurrent tasks in a program.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q3. Write a python code to create a process using the multiprocessing module.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q3 Solution :\n\nCertainly! Here's an example of creating a process using the `multiprocessing` module in Python:\n\n```python\nimport multiprocessing\n\n# Define a function to be executed by the process\ndef worker(num):\n    print(f\"Worker process with argument {num}\")\n\nif __name__ == \"__main__\":\n    # Create a process object with target function and argument\n    process = multiprocessing.Process(target=worker, args=(123,))\n    \n    # Start the process\n    process.start()\n    \n    # Wait for the process to complete\n    process.join()\n```\n\nIn this code:\n\n- We import the `multiprocessing` module.\n- Define a function `worker` that takes an argument `num` and prints a message.\n- Check if the script is running as the main module using `if __name__ == \"__main__\":` to avoid issues on Windows systems.\n- Create a process object `process` using `multiprocessing.Process` with the target function `worker` and an argument `(123,)`.\n- Start the process using `process.start()`.\n- Wait for the process to complete using `process.join()`.\n\nWhen you run this code, it will create a new process that executes the `worker` function with the argument `123`. You should see the output message from the `worker` function executed by the new process.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q4. What is a multiprocessing pool in python? Why is it used?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q4. Solution :\n\nA multiprocessing pool in Python refers to a collection of worker processes that can be utilized to execute tasks concurrently. It provides a convenient way to distribute work among multiple processes, particularly when dealing with CPU-bound tasks or performing computations that can be parallelized.\n\n### Features and Usage of Multiprocessing Pool:\n\n1. **Parallel Execution**:\n   - A multiprocessing pool allows multiple processes to execute tasks in parallel, leveraging multiple CPU cores or processors. This can significantly improve the performance of CPU-bound tasks by distributing the workload.\n\n2. **Worker Processes**:\n   - The pool consists of a specified number of worker processes that are created when the pool is initialized. These worker processes remain active and can be reused to execute multiple tasks concurrently.\n\n3. **Task Distribution**:\n   - Tasks are submitted to the pool using the `apply()`, `apply_async()`, `map()`, or `map_async()` methods. The pool automatically assigns tasks to available worker processes for execution.\n\n4. **Efficient Resource Utilization**:\n   - Multiprocessing pools manage the creation and management of worker processes, optimizing resource utilization and reducing overhead compared to creating and managing processes manually.\n\n5. **Concurrency and Scalability**:\n   - By utilizing a multiprocessing pool, Python programs can achieve concurrency and scalability by executing tasks concurrently across multiple CPU cores. This is particularly beneficial for computationally intensive tasks.\n\n6. **Asynchronous Execution**:\n   - The pool provides asynchronous execution capabilities through methods like `apply_async()` and `map_async()`, allowing tasks to run concurrently without blocking the main program flow.\n\n7. **Result Retrieval**:\n   - After submitting tasks to the pool, results can be retrieved using the `get()` method or by specifying callback functions for asynchronous execution. This enables synchronization and processing of task outcomes.\n\n### Example Usage of Multiprocessing Pool:\n\n```python\nimport multiprocessing\n\n# Define a function to be executed by worker processes\ndef square(x):\n    return x * x\n\nif __name__ == \"__main__\":\n    # Create a multiprocessing pool with 4 worker processes\n    pool = multiprocessing.Pool(processes=4)\n    \n    # Map the 'square' function to a list of input values\n    input_values = [1, 2, 3, 4, 5]\n    results = pool.map(square, input_values)\n    \n    # Close the pool and wait for all processes to complete\n    pool.close()\n    pool.join()\n    \n    # Print the results\n    print(\"Squared Values:\", results)\n```\n\nIn this example, we create a multiprocessing pool with 4 worker processes using `multiprocessing.Pool`. We then use the `map()` method to apply the `square` function to a list of input values concurrently. The pool automatically distributes the tasks among the worker processes, and the results are collected in the `results` list. Finally, we close the pool and print the squared values obtained from the worker processes.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q5. How can we create a pool of worker processes in python using the multiprocessing module?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q5. Solution :\n\nTo create a pool of worker processes in Python using the `multiprocessing` module, you can follow these steps:\n\n1. Import the `multiprocessing` module.\n2. Create an instance of `multiprocessing.Pool` specifying the desired number of worker processes.\n3. Use the pool's methods (`map()`, `apply()`, `apply_async()`, etc.) to submit tasks to the pool for execution.\n4. Close the pool and join the processes to wait for all tasks to complete and resources to be released.\n\nHere's an example demonstrating how to create a pool of worker processes and execute tasks concurrently:\n\n```python\nimport multiprocessing\n\n# Function to be executed by worker processes\ndef square(x):\n    return x * x\n\nif __name__ == \"__main__\":\n    # Create a multiprocessing pool with 4 worker processes\n    pool = multiprocessing.Pool(processes=4)\n    \n    # List of input values\n    input_values = [1, 2, 3, 4, 5]\n    \n    # Use map() method to apply the 'square' function to input values concurrently\n    results = pool.map(square, input_values)\n    \n    # Close the pool to prevent any more tasks from being submitted\n    pool.close()\n    \n    # Wait for all worker processes to complete\n    pool.join()\n    \n    # Print the results\n    print(\"Squared Values:\", results)\n```\n\nIn this example:\n\n- We import the `multiprocessing` module.\n- Create a pool of 4 worker processes using `multiprocessing.Pool(processes=4)`.\n- Define a function `square(x)` that squares its input.\n- Create a list of input values `[1, 2, 3, 4, 5]`.\n- Use the `map()` method of the pool to apply the `square` function to each input value concurrently, resulting in squared values stored in the `results` list.\n- Close the pool using `pool.close()` to prevent further tasks from being submitted.\n- Use `pool.join()` to wait for all worker processes to complete their tasks.\n- Finally, print the squared values obtained from the worker processes.\n\nThis approach allows for efficient concurrent execution of tasks across multiple worker processes in a pool, leveraging multiprocessing capabilities to improve performance and resource utilization.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q6. Write a python program to create 4 processes, each process should print a different number using the\nmultiprocessing module in python.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Q6. Solution \n\nCertainly! Here's a Python program that creates 4 processes, and each process prints a different number using the `multiprocessing` module:\n\n```python\nimport multiprocessing\n\n# Function to be executed by each process\ndef print_number(num):\n    print(f\"Process {num}: {num}\")\n\nif __name__ == \"__main__\":\n    # Create a list of numbers for each process\n    numbers = [1, 2, 3, 4]\n    \n    # Create a list to hold process objects\n    processes = []\n    \n    # Create and start processes\n    for num in numbers:\n        process = multiprocessing.Process(target=print_number, args=(num,))\n        processes.append(process)\n        process.start()\n    \n    # Wait for all processes to complete\n    for process in processes:\n        process.join()\n```\n\nIn this program:\n\n- We import the `multiprocessing` module.\n- Define a function `print_number(num)` that prints a given number along with the process number.\n- Create a list of numbers `[1, 2, 3, 4]` representing the numbers to be printed by each process.\n- Create an empty list `processes` to hold the process objects.\n- Iterate through the numbers list and create a process for each number using `multiprocessing.Process`. Each process targets the `print_number` function with the corresponding number as an argument.\n- Append each process object to the `processes` list and start each process using `process.start()`.\n- Use `process.join()` to wait for all processes to complete before exiting the program.\n\nWhen you run this program, each process will print its assigned number, and the output will show the numbers printed by each process in a non-deterministic order due to concurrent execution.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}